# Lake Analysis Pipeline Agent

A multi-step LLM-powered pipeline for answering natural language questions about DoubleZero network and Solana validator data.

## Overview

The analysis pipeline transforms natural language questions into SQL queries, executes them against ClickHouse, and synthesizes the results into comprehensive answers. Unlike a ReAct-style agent that loops until done, this pipeline uses discrete, well-defined steps for predictability and debuggability.

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              User Question                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CLASSIFY (Pre-step)                                 â”‚
â”‚  Determines how to route the question:                                      â”‚
â”‚  â€¢ data_analysis â†’ full pipeline                                            â”‚
â”‚  â€¢ conversational â†’ direct response (no data query)                         â”‚
â”‚  â€¢ out_of_scope â†’ polite rejection                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                     â”‚                     â”‚
            â–¼                     â–¼                     â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚out_of_   â”‚          â”‚conversa- â”‚          â”‚  data_   â”‚
     â”‚scope     â”‚          â”‚tional    â”‚          â”‚ analysis â”‚
     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
          â”‚                     â”‚                     â”‚
          â–¼                     â–¼                     â”‚
    Direct message          RESPOND                   â”‚
    (capabilities)       (uses history)               â”‚
          â”‚                     â”‚                     â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
                     â”‚                                â”‚
                     â”‚                                â–¼
                     â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚         â”‚              DECOMPOSE (Step 1)          â”‚
                     â”‚         â”‚  Breaks question into data questions     â”‚
                     â”‚         â”‚  â€¢ Domain terminology mapping            â”‚
                     â”‚         â”‚  â€¢ Multi-faceted question breakdown      â”‚
                     â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚                           â”‚
                     â”‚                           â–¼
                     â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚         â”‚           GENERATE (Step 2)              â”‚
                     â”‚         â”‚  Creates SQL for each data question      â”‚
                     â”‚         â”‚  â€¢ Dynamic schema injection              â”‚
                     â”‚         â”‚  â€¢ Sample values for enums               â”‚
                     â”‚         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                     â”‚         â”‚  â”‚ Runs in PARALLEL for each question â”‚  â”‚
                     â”‚         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                     â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚                           â”‚
                     â”‚                           â–¼
                     â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚         â”‚            EXECUTE (Step 3)              â”‚
                     â”‚         â”‚  Runs SQL against ClickHouse             â”‚
                     â”‚         â”‚  â€¢ Automatic retry on errors             â”‚
                     â”‚         â”‚  â€¢ Zero-row analysis & regeneration      â”‚
                     â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚                           â”‚
                     â”‚                           â–¼
                     â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚         â”‚           SYNTHESIZE (Step 4)            â”‚
                     â”‚         â”‚  Combines results into final answer      â”‚
                     â”‚         â”‚  â€¢ Confidence assessment                 â”‚
                     â”‚         â”‚  â€¢ Citation generation [Q1], [Q2]        â”‚
                     â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚                           â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                                                 â”‚
                                                 â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚               Final Answer                â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Pipeline Steps

### Pre-step: Classify

Routes questions to the appropriate handler based on intent:

| Classification | Description | Handler |
|---------------|-------------|---------|
| `data_analysis` | Questions requiring database queries | Full pipeline |
| `conversational` | Follow-ups, clarifications, capabilities | Direct LLM response |
| `out_of_scope` | Unrelated questions | Polite rejection |

**Examples:**
- "How many validators are connected?" â†’ `data_analysis`
- "What do you mean by that?" â†’ `conversational`
- "What's the weather today?" â†’ `out_of_scope`

### Step 1: Decompose

Breaks a complex user question into specific, queryable data questions.

**Input:** Natural language question + conversation history
**Output:** Array of `DataQuestion` with question text and rationale

**Features:**
- Domain terminology mapping (e.g., "active" â†’ `status = 'activated'`)
- Multi-faceted breakdown (e.g., "network health" â†’ device status, link status, latency, errors)
- Comparison awareness (e.g., "validators connected today" â†’ current vs historical)

**Example:**
```
User: "How is the network performing?"

Data Questions:
1. How many devices are in activated status? (baseline operational count)
2. How many links are in activated status? (connectivity health)
3. What is the average and P95 latency across WAN links in the last 24h? (performance)
4. Which links have packet loss > 0.1% in the last 24h? (quality issues)
```

### Step 2: Generate

Creates SQL queries for each data question using dynamic schema context.

**Input:** Data question + live database schema
**Output:** `GeneratedQuery` with SQL and explanation

**Features:**
- **Dynamic schema injection**: Fetches current table/column info from ClickHouse
- **Sample value hints**: Includes actual enum values (e.g., `status` values: activated, pending, suspended)
- **ClickHouse-aware**: Handles ClickHouse-specific syntax and behaviors

### Step 3: Execute

Runs SQL queries against ClickHouse with intelligent error recovery.

**Input:** Generated SQL query
**Output:** `ExecutedQuery` with results or error

**Features:**
- **Parallel execution**: All data questions run concurrently
- **Retry on error**: Up to 4 retries with error context for regeneration
- **Zero-row analysis**: Detects suspicious empty results and regenerates

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Error Recovery Flow                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Execute Query                                              â”‚
â”‚       â”‚                                                     â”‚
â”‚       â”œâ”€â”€ Success with rows â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Return      â”‚
â”‚       â”‚                                                     â”‚
â”‚       â”œâ”€â”€ Success with 0 rows                               â”‚
â”‚       â”‚        â”‚                                            â”‚
â”‚       â”‚        â–¼                                            â”‚
â”‚       â”‚   Analyze Zero Result                               â”‚
â”‚       â”‚        â”‚                                            â”‚
â”‚       â”‚        â”œâ”€â”€ Expected (e.g., count=0) â”€â”€â–º Return      â”‚
â”‚       â”‚        â”‚                                            â”‚
â”‚       â”‚        â””â”€â”€ Suspicious â”€â”€â–º Regenerate & Retry        â”‚
â”‚       â”‚                                                     â”‚
â”‚       â””â”€â”€ Error                                             â”‚
â”‚                â”‚                                            â”‚
â”‚                â–¼                                            â”‚
â”‚           Regenerate with error context                     â”‚
â”‚                â”‚                                            â”‚
â”‚                â””â”€â”€ Retry (up to 4 times)                    â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Step 4: Synthesize

Combines query results into a coherent, cited answer.

**Input:** User question + all executed queries with results
**Output:** Formatted answer with citations

**Features:**
- **Confidence tracking**: HIGH/MEDIUM/LOW based on query success
- **Citation format**: `[Q1]`, `[Q2]` references to data sources
- **Structured output**: Headers, bullet points, appropriate units
- **Anomaly highlighting**: Calls out concerning values

**Example output:**
```
ğŸ”Œ **Device Status**
- 75 devices activated [Q1]
- 0 devices in other states [Q1]

ğŸ”— **Link Health**
- 128 links activated [Q2]
- 3 links showing packet loss > 0.1% [Q3]:
  - `nyc-lon-1`: 2.5% loss
  - `tok-sgp-1`: 0.8% loss

âš ï¸ **Attention Required**
- `nyc-lon-1` packet loss elevated from baseline [Q3, Q4]
```

## Domain Knowledge

The pipeline includes extensive domain context in prompts:

### Network Concepts
- **Devices**: Routers/switches in the DZ network
- **Links**: Connections between devices (WAN = inter-metro, DZX = intra-metro)
- **Metros**: Data center locations (NYC, LON, TOK, etc.)
- **Contributors**: Operators who manage devices and links

### User Types
- **Multicast**: `kind = 'multicast'` - receives multicast streams
- **Unicast**: `kind = 'ibrl'` or `'ibrl_with_allocated_ip'`
- **Edge filtering**: `kind = 'edge_filtering'`

### Solana Integration
- **Validators**: Connected via `dz_users.dz_ip = solana_gossip_nodes.gossip_ip`
- **Stake**: `activated_stake_lamports` on vote accounts
- **Vote lag**: `cluster_slot - last_vote_slot`

### Status Values
- `pending`, `activated`, `suspended`, `deleted`, `rejected`, `drained`
- "Active" typically means `status = 'activated'`

## Usage

```go
package main

import (
    "context"
    "github.com/malbeclabs/doublezero/lake/agent/pkg/pipeline"
)

func main() {
    // Load prompts from embedded files
    prompts, _ := pipeline.LoadPrompts()

    // Create pipeline
    p, _ := pipeline.New(&pipeline.Config{
        LLM:           myLLMClient,      // implements pipeline.LLMClient
        Querier:       myQuerier,        // implements pipeline.Querier
        SchemaFetcher: mySchemaFetcher,  // implements pipeline.SchemaFetcher
        Prompts:       prompts,
        MaxRetries:    4,
    })

    // Run a query
    result, err := p.Run(ctx, "How many validators are connected to DZ?")
    if err != nil {
        log.Fatal(err)
    }

    fmt.Println(result.Answer)
    fmt.Printf("Classification: %s\n", result.Classification)
    fmt.Printf("Data questions: %d\n", len(result.DataQuestions))
}
```

### With Conversation History

```go
history := []pipeline.ConversationMessage{
    {Role: "user", Content: "How many validators are connected?"},
    {Role: "assistant", Content: "There are 150 validators connected..."},
}

result, err := p.RunWithHistory(ctx, "What about their total stake?", history)
```

## Interfaces

### LLMClient

```go
type LLMClient interface {
    Complete(ctx context.Context, systemPrompt, userPrompt string) (string, error)
}
```

### Querier

```go
type Querier interface {
    Query(ctx context.Context, sql string) (QueryResult, error)
}
```

### SchemaFetcher

```go
type SchemaFetcher interface {
    FetchSchema(ctx context.Context) (string, error)
}
```

## File Structure

```
agent/
â”œâ”€â”€ pkg/pipeline/
â”‚   â”œâ”€â”€ pipeline.go      # Main orchestration, PipelineResult, Config
â”‚   â”œâ”€â”€ classify.go      # Question classification (pre-step)
â”‚   â”œâ”€â”€ decompose.go     # Question decomposition (step 1)
â”‚   â”œâ”€â”€ generate.go      # SQL generation + retry logic (step 2)
â”‚   â”œâ”€â”€ execute.go       # Query execution (step 3)
â”‚   â”œâ”€â”€ synthesize.go    # Answer synthesis (step 4)
â”‚   â”œâ”€â”€ respond.go       # Conversational responses
â”‚   â”œâ”€â”€ schema.go        # Dynamic schema fetching
â”‚   â”œâ”€â”€ anthropic.go     # Anthropic LLM client implementation
â”‚   â”œâ”€â”€ querier.go       # Query result formatting
â”‚   â”œâ”€â”€ prompts.go       # Prompt loading
â”‚   â””â”€â”€ prompts/
â”‚       â”œâ”€â”€ CATALOG_SUMMARY.md   # Data catalog overview
â”‚       â”œâ”€â”€ CLASSIFY.md          # Classification prompt
â”‚       â”œâ”€â”€ DECOMPOSE.md         # Decomposition prompt
â”‚       â”œâ”€â”€ GENERATE.md          # SQL generation prompt
â”‚       â”œâ”€â”€ RESPOND.md           # Conversational response prompt
â”‚       â”œâ”€â”€ SYNTHESIZE.md        # Answer synthesis prompt
â”‚       â””â”€â”€ embed.go             # Embeds prompts into binary
â””â”€â”€ evals/
    â”œâ”€â”€ helpers_test.go                    # Test utilities
    â”œâ”€â”€ conversational_followup_test.go    # Conversational handling tests
    â”œâ”€â”€ unrelated_question_no_data_test.go # Out-of-scope tests
    â”œâ”€â”€ solana_validators_*.go             # Solana-related evals
    â””â”€â”€ network_*.go                       # Network-related evals
```

## Evaluation Tests

The `evals/` directory contains end-to-end tests that validate pipeline behavior using real LLM calls. Tests support both Anthropic and local Ollama backends.

```bash
# Run with Anthropic
ANTHROPIC_API_KEY=... go test -tags evals ./evals/...

# Run with Ollama (local)
go test -tags evals ./evals/...

# Enable debug output
DEBUG=1 go test -tags evals -run TestName ./evals/...
```

## Design Decisions

### Why a Pipeline Instead of ReAct?

1. **Predictability**: Fixed steps mean consistent latency and cost
2. **Debuggability**: Each step's output is inspectable
3. **Parallelization**: Data questions execute concurrently
4. **Separation of concerns**: Each step has a single responsibility

### Why Dynamic Schema?

- Schemas evolve; embedding static schema would require redeployment
- Sample values help the LLM use correct enum values
- View definitions provide query hints

### Why Classification Pre-step?

- Avoids unnecessary database queries for conversational questions
- Provides natural handling of follow-ups and clarifications
- Graceful handling of out-of-scope questions

### Why Zero-Row Analysis?

- Empty results are often caused by incorrect filter values
- LLM can reason about whether zero rows is expected
- Automatic regeneration improves success rate without user intervention
